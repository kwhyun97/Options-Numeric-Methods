{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<left>FINM 32000 - Numerical Methods</left>\n",
    "<left>Spring 2023</left>\n",
    "<br>\n",
    "<h1><center> Homework 7 </center></h1>\n",
    "<center>Due - 23:59 [CST] May 19th, 2023</center>\n",
    "<br>\n",
    "<h3>Ki Hyun</h3>\n",
    "<h3>Student ID: 12125881</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import scipy.optimize\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Helper-Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GBM:\n",
    "\n",
    "    def __init__(self,S0,r,sigma):\n",
    "        self.S0 = S0\n",
    "        self.r = r\n",
    "        self.sigma = sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Put:\n",
    "    \n",
    "    def __init__(self,K,T):\n",
    "        self.K = K\n",
    "        self.T = T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MC:\n",
    "    \n",
    "    def __init__(self,M,N,seed,algorithm):\n",
    "        \n",
    "        self.M = M # Number of paths  \n",
    "        self.N = N     # Number of time periods  \n",
    "        self.rng = np.random.default_rng(seed=seed) # Seeding the random number generator with a specified number helps make the calculations reproducible\n",
    "\n",
    "        self.algorithm = algorithm   \n",
    "        #'value' for Value-based approach (Longstaff-Schwartz) -- problem 1a\n",
    "        #'policy' for Policy optimization -- problem 1b\n",
    "    \n",
    "    def price_americanPut_GBM(self,contract,dynamics):\n",
    "\n",
    "        r=dynamics.r\n",
    "        sigma=dynamics.sigma\n",
    "        S0=dynamics.S0\n",
    "\n",
    "        K=contract.K\n",
    "        T=contract.T\n",
    "\n",
    "        N=self.N\n",
    "        M=self.M\n",
    "        dt=T/N\n",
    "\n",
    "        Z = self.rng.normal(size=(M,N))\n",
    "\n",
    "        paths = S0*np.exp((r-sigma**2/2)*dt*np.tile(np.arange(1,N+1),(M,1))+sigma*np.sqrt(dt)*np.cumsum(Z,axis=1))\n",
    "\n",
    "        payoffDiscounted = np.maximum(0,K-paths[:,-1])\n",
    "        #This is the payoff (cashflow) along each path,\n",
    "        #discounted to time nn (for nn=N,N-1,...)\n",
    "        #It corresponds to the far right-hand column in each page of the\n",
    "        #Excel worksheet\n",
    "        #I'm initializing it for time nn=N.\n",
    "\n",
    "        #You could make payoffDiscounted\n",
    "        #to be a matrix because it depends on nn.\n",
    "        #But I will just reuse a 1-dimensional array,\n",
    "        #by overwriting the time nn+1 entries at time nn.        \n",
    "\n",
    "        for nn in np.arange(N-1,0,-1):\n",
    "            continuationPayoffDiscounted = np.exp(-r*dt)*payoffDiscounted\n",
    "            # This is the CONTINUATION payoff (cashflow) along each path,\n",
    "            # discounted to time nn (for nn=N-1,N-2,...)\n",
    "            # It corresponds to the blue column in each page of the Excel worksheet\n",
    "            # Note that payoffDiscounted comes from the previous iteration \n",
    "            # -- which was at time nn+1.  So now we discount back to time nn.\n",
    "\n",
    "            X=paths[:,nn-1]               \n",
    "            exerciseValue = K-X\n",
    "\n",
    "            if self.algorithm == 'value': \n",
    "                # This is the value function (Longstaff-Schwartz) approach.  For problem 1a\n",
    "\n",
    "                basisfunctions = np.stack((np.ones(M), X, X**2), axis = 1)# FILL THIS IN.  You may use np.stack\n",
    "                        # This will be an M-by-3 array containing the basis functions (Same ones as L7.9-7.10, and Excel)\n",
    "\n",
    "                # conducting regression only on the paths that are in-the-money\n",
    "                A = basisfunctions[(exerciseValue > 0), :]\n",
    "                y = continuationPayoffDiscounted[exerciseValue > 0]\n",
    "                lm = LinearRegression()\n",
    "                lm.fit(X = A, y = y)\n",
    "                coefficients = lm.coef_ # FILL THIS IN\n",
    "                        # This will be an array of 3 estimated \"betas\".\n",
    "\n",
    "                estimatedContinuationValue = np.dot(basisfunctions, coefficients) # FILL THIS IN\n",
    "                        # with an array of length M.\n",
    "                        # This is similar to the Red column in Excel\n",
    "\n",
    "                whichPathsToExercise = (exerciseValue >= np.maximum(estimatedContinuationValue,0))\n",
    "                        #This is a length-M array of Booleans\n",
    "\n",
    "            elif self.algorithm == 'policy':\n",
    "                # This is the policy optimization approach to Reinforcement learning.  For problem 1b\n",
    "\n",
    "                (a_opt,b_opt) = scipy.optimize.minimize(negofMCaverageOfExpectedPayouts,(0,0),\n",
    "                                                        args=(X,exerciseValue,continuationPayoffDiscounted),\n",
    "                                                        method='Nelder-Mead').x\n",
    "                    #Chose Nelder-Mead optimizer because it is generating reasonable results with minimal coding effort\n",
    "                    #But gradient methods, done properly, usually run faster\n",
    "\n",
    "                whichPathsToExercise = ((softExercise(X, a_opt, b_opt) >= 0.5) & (exerciseValue > 0))\n",
    "                    #FILL THIS IN, using the right-hand side of the last equation on the homework sheet \n",
    "                    #This obtains the hard exercise decision from the optimized soft exercise function\n",
    "                    #It should be a length-M array of Booleans (as it was in the \"value\" approach.  \n",
    "                    #But here it comes from the softExercise function)\n",
    "\n",
    "            else:\n",
    "                raise ValueError('Unknown algorithm type')\n",
    "\n",
    "\n",
    "            payoffDiscounted[whichPathsToExercise] = exerciseValue[whichPathsToExercise]\n",
    "            # FILL THIS IN -- see the\n",
    "                # \"discounted cashflow along path\"\n",
    "            # column in Excel\n",
    "            payoffDiscounted[np.logical_not(whichPathsToExercise)] = continuationPayoffDiscounted[np.logical_not(whichPathsToExercise)]\n",
    "            # FILL THIS IN -- see the\n",
    "                # \"discounted cashflow\n",
    "            # along path\" column in Excel\n",
    "\n",
    "        # The time-0 calculation needs no regression\n",
    "        continuationPayoffDiscounted = np.exp(-r*dt)*payoffDiscounted\n",
    "        estimatedContinuationValue = np.mean(continuationPayoffDiscounted)\n",
    "        putprice = max(K-S0,estimatedContinuationValue)\n",
    "\n",
    "        return(putprice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Policy optimization approach, problem 1b\n",
    "#\n",
    "# If b<<0 then this function essentially returns nearly 1 if X<a, or nearly 0 if X>a\n",
    "# but with some smoothing of the discontinuity, using a sigmoid function, to help the optimizer\n",
    "\n",
    "def softExercise(X,a,b):\n",
    "    return 1/(1+np.exp(-b*(X-a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Policy optimization approach, problem 1b\n",
    "\n",
    "def negofMCaverageOfExpectedPayouts(coefficients, x, exercisePayoff, continuationPayoff):\n",
    "\n",
    "    p = softExercise(x,*coefficients)    \n",
    "\n",
    "    # p and exercisePayoff and continuationPayoff are all length-M arrays\n",
    "\n",
    "    return -np.mean(p * exercisePayoff + (1 - p) * continuationPayoff)# FILL THIS IN\n",
    "\n",
    "## You fill in, what to return.  It should be the negative of the expression inside the max() on the homework sheet.\n",
    "## Need to take the negative because we are calling \"minimize\" but we want to do _maximization_"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Problem 1."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "hw7dynamics = GBM(S0=1, r=0.03, sigma=0.20)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "hw7contract = Put(K=1.1, T=4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### (Problem 1a)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "hw7MC_a = MC(M=10000, N=4, seed=0, algorithm='value')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.13779107851434708"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hw7MC_a.price_americanPut_GBM(hw7contract,hw7dynamics)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### (Problem 1b)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "hw7MC_b = MC(M=10000, N=4, seed=0, algorithm='policy')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "0.16263529459015832"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hw7MC_b.price_americanPut_GBM(hw7contract,hw7dynamics)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Problem 2."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## (a)\n",
    "\n",
    "The 2nd derivative of $F(u, v)$ with respect to $u$ is:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\delta^2}{\\delta u^2} F(u, v) &=\n",
    "\\mathbf{E}[(iR_1)^2 e^{iuR_1 + ivR_2}] \\\\\n",
    "&= \\mathbf{E}[-R_1^2 e^{iuR_1 + ivR_2}] \\\\\n",
    "&= -\\mathbf{E}[R_1^2 e^{iuR_1 + ivR_2}]\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "If we evaluate this second derivative at $u = 0, v = 0$:\n",
    "\n",
    "$$\n",
    "\\frac{\\delta^2}{\\delta u^2} F(0, 0) =\n",
    "-\\mathbf{E}[R_1^2]\n",
    "$$\n",
    "\n",
    "Similarly, 2nd derivative of $F(u, v)$ with respect to $v$ is:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\delta^2}{\\delta v^2} F(u, v) &=\n",
    "\\mathbf{E}[(iR_2)^2 e^{iuR_1 + ivR_2}] \\\\\n",
    "&= \\mathbf{E}[-R_2^2 e^{iuR_1 + ivR_2}] \\\\\n",
    "&= -\\mathbf{E}[R_2^2 e^{iuR_1 + ivR_2}]\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "If we evaluate this second derivative at $u = 0, v = 0$:\n",
    "\n",
    "$$\n",
    "\\frac{\\delta^2}{\\delta v^2} F(0, 0) =\n",
    "-\\mathbf{E}[R_2^2]\n",
    "$$\n",
    "\n",
    "Since we know that\n",
    "\n",
    "$$\n",
    "\\mathbf{E}(R_1^2 + R_2^2) =\n",
    "\\mathbf{E}(R_1^2) + \\mathbf{E}(R_2^2)\n",
    "$$\n",
    "\n",
    "The answer in terms of $F$ would be:\n",
    "\n",
    "$$\n",
    "\\mathbf{E}(R_1^2 + R_2^2) = - \\frac{\\delta^2}{\\delta u^2} F(0, 0) -\n",
    "\\frac{\\delta^2}{\\delta v^2} F(0, 0)\n",
    "$$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## (b)\n",
    "\n",
    "By definition:\n",
    "\n",
    "$$\n",
    "\\psi(w) := \\mathbf{E}[e^{iw(4R_1 - 3R_2)}]\n",
    "$$\n",
    "\n",
    "Furthermore,\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbf{E}[e^{iw(4R_1 - 3R_2)}] &=\n",
    "\\mathbf{E}[e^{i4wR_1 - 3wR_2}] \\\\\n",
    "&= F(4w, -3w)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Therefore, $\\psi(w)$ can be expressed as $F(4w, -3w)$."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## (c)\n",
    "\n",
    "Again, by definition,\n",
    "\n",
    "$$\n",
    "G(x, y) := \\mathbf{E} e^{ixR_3 + iyR_4}\n",
    "$$\n",
    "\n",
    "Additionally,\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbf{E} e^{ixR_3 + iyR_4} &=\n",
    "\\mathbf{E} e^{ixR_3} \\times e^{iyR_4} \\\\\n",
    "&= (\\mathbf{E} e^{ixR_3}) \\times (\\mathbf{E} e^{iyR_4}) \\\\\n",
    "&(\\because R_3 \\perp\\!\\!\\!\\perp R_4) \\\\\n",
    "&= (\\mathbf{E} e^{ixR_1}) \\times (\\mathbf{E} e^{iyR_2}) \\\\\n",
    "&(\\because R_3 \\sim R_1, \\ R_4 \\sim R_2) \\\\\n",
    "&= F(x, 0) \\times F(0, y)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Ultimately,\n",
    "\n",
    "$$\n",
    "G(x, y) = F(x, 0) \\times F(0, y)\n",
    "$$"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
